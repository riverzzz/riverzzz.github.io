<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  

  
  <title>读 Deep Neural Networks for YouTube Recommendations  总结 | welcome，my github</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="下面是DNN推荐的描述及我的理解 DNN推荐架构下图是youtube推荐系统的架构图，和其他推荐系统一样，包括召回和排序这两个阶段，主要使用了深度学习。 召回阶段召回问题建模youtube把召回阶段建模成了一个“超多大规模分类”问题。即在时刻t，为用户U（上下文信息C）在视频库V中精准的预测出视频i的类别（每个具体的视频视为一个类别，i即为一个类别），用数学公式表达如下：很显然上式为一个softm">
<meta property="og:type" content="article">
<meta property="og:title" content="读 Deep Neural Networks for YouTube Recommendations  总结">
<meta property="og:url" content="https://riverzzz.github.io/2018/12/19/读-Deep-Neural-Networks-for-YouTube-Recommendations-总结/index.html">
<meta property="og:site_name" content="welcome，my github">
<meta property="og:description" content="下面是DNN推荐的描述及我的理解 DNN推荐架构下图是youtube推荐系统的架构图，和其他推荐系统一样，包括召回和排序这两个阶段，主要使用了深度学习。 召回阶段召回问题建模youtube把召回阶段建模成了一个“超多大规模分类”问题。即在时刻t，为用户U（上下文信息C）在视频库V中精准的预测出视频i的类别（每个具体的视频视为一个类别，i即为一个类别），用数学公式表达如下：很显然上式为一个softm">
<meta property="og:locale" content="default">
<meta property="og:image" content="https://riverzzz.github.io/2018/12/19/读-Deep-Neural-Networks-for-YouTube-Recommendations-总结/DNN推荐架构图.png">
<meta property="og:image" content="https://riverzzz.github.io/2018/12/19/读-Deep-Neural-Networks-for-YouTube-Recommendations-总结/召回分类公式.png">
<meta property="og:image" content="https://riverzzz.github.io/2018/12/19/读-Deep-Neural-Networks-for-YouTube-Recommendations-总结/召回模型架构图.png">
<meta property="og:image" content="https://riverzzz.github.io/2018/12/19/读-Deep-Neural-Networks-for-YouTube-Recommendations-总结/days-since-upload.png">
<meta property="og:image" content="https://riverzzz.github.io/2018/12/19/读-Deep-Neural-Networks-for-YouTube-Recommendations-总结/数据集划分.png">
<meta property="og:image" content="https://riverzzz.github.io/2018/12/19/读-Deep-Neural-Networks-for-YouTube-Recommendations-总结/特征和网络结构效果对比.png">
<meta property="og:image" content="https://riverzzz.github.io/2018/12/19/读-Deep-Neural-Networks-for-YouTube-Recommendations-总结/排序模型架构.png">
<meta property="og:image" content="https://riverzzz.github.io/2018/12/19/读-Deep-Neural-Networks-for-YouTube-Recommendations-总结/期望观看时长.png">
<meta property="og:updated_time" content="2018-12-23T13:39:28.139Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="读 Deep Neural Networks for YouTube Recommendations  总结">
<meta name="twitter:description" content="下面是DNN推荐的描述及我的理解 DNN推荐架构下图是youtube推荐系统的架构图，和其他推荐系统一样，包括召回和排序这两个阶段，主要使用了深度学习。 召回阶段召回问题建模youtube把召回阶段建模成了一个“超多大规模分类”问题。即在时刻t，为用户U（上下文信息C）在视频库V中精准的预测出视频i的类别（每个具体的视频视为一个类别，i即为一个类别），用数学公式表达如下：很显然上式为一个softm">
<meta name="twitter:image" content="https://riverzzz.github.io/2018/12/19/读-Deep-Neural-Networks-for-YouTube-Recommendations-总结/DNN推荐架构图.png">
  
    <link rel="alternate" href="/atom.xml" title="welcome，my github" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">welcome，my github</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://riverzzz.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-读-Deep-Neural-Networks-for-YouTube-Recommendations-总结" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2018/12/19/读-Deep-Neural-Networks-for-YouTube-Recommendations-总结/" class="article-date">
  <time datetime="2018-12-19T15:04:18.000Z" itemprop="datePublished">2018-12-19</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      读 Deep Neural Networks for YouTube Recommendations  总结
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>下面是DNN推荐的描述及我的理解</p>
<h2 id="DNN推荐架构"><a href="#DNN推荐架构" class="headerlink" title="DNN推荐架构"></a>DNN推荐架构</h2><p>下图是youtube推荐系统的架构图，和其他推荐系统一样，包括召回和排序这两个阶段，主要使用了深度学习。<br><img src="/2018/12/19/读-Deep-Neural-Networks-for-YouTube-Recommendations-总结/DNN推荐架构图.png" title="DNN推荐架构图"></p>
<h2 id="召回阶段"><a href="#召回阶段" class="headerlink" title="召回阶段"></a>召回阶段</h2><h3 id="召回问题建模"><a href="#召回问题建模" class="headerlink" title="召回问题建模"></a>召回问题建模</h3><p>youtube把召回阶段建模成了一个“超多大规模分类”问题。即在时刻t，为用户U（上下文信息C）在视频库V中精准的预测出视频i的<br>类别（每个具体的视频视为一个类别，i即为一个类别），用数学公式表达如下：<br><img src="/2018/12/19/读-Deep-Neural-Networks-for-YouTube-Recommendations-总结/召回分类公式.png" title="分类公式"><br>很显然上式为一个softmax多分类器的形式。向量u\in R^N是&lt;user, context&gt;信息的高维“embedding”，而向量v_{j}\in R^N则是<br>视频 j 的embedding向量。所以DNN的目标就是在用户信息和上下文信息为输入条件下学习用户的embedding向量u和视频的embedding向<br>量v。用公式表达DNN就是在拟合函数u,v = f_{DNN}(user_info, context_info)。</p>
<h3 id="模型架构"><a href="#模型架构" class="headerlink" title="模型架构"></a>模型架构</h3><img src="/2018/12/19/读-Deep-Neural-Networks-for-YouTube-Recommendations-总结/召回模型架构图.png" title="召回模型架构图">
<p>模型是一个三层的网络架构，主要输入是观看、搜索历史，样本时间，用户场景信息以及用户画像信息等。<br>主要分为离线训练及线上服务两个部分。离线输出为softmax层，计算公式为之前提到的公式。而线上将训练得到的视频embedding向量v<br>存储起来，实时根据模型计算出用户向量u，然后利用lsh技术找到内积最近的topN。</p>
<h3 id="主要特征"><a href="#主要特征" class="headerlink" title="主要特征"></a>主要特征</h3><p>1.观看历史和搜索历史：类似于word2vec每个视频embedding到固定维度的向量中。最终通过加权平均（重要性和时间）得到固定维度的<br>watch vector作为DNN的输入。<br>2.人口统计学信息：性别、年龄、地域等<br>3.上下文信息：设备、登陆状态、位置等<br>4.Example Age： 样本时间，表示样本产生的时间。因为机器学习系统在训练阶段都是利用过去的行为预估未来，因此通常对过去的行为<br>有个隐式的bias。视频网站视频的分布是高度非静态（non-stationary）的，但我们的推荐系统产生的视频集合在视频的分布，基本上反<br>映的是训练所取时间段的平均的观看喜好的视频。因此我们我们把样本的 “age” 作为一个feature加入模型训练中。从下图可以很清楚的<br>看出，加入“example age” feature后和经验分布更为match。<br><img src="/2018/12/19/读-Deep-Neural-Networks-for-YouTube-Recommendations-总结/days-since-upload.png" title="days-since-upload"></p>
<h3 id="样本和上下文选择"><a href="#样本和上下文选择" class="headerlink" title="样本和上下文选择"></a>样本和上下文选择</h3><p>在有监督学习问题中，最重要的选择是label了，因为label决定了你做什么，决定了你的上限，而feature和model都是在逼近label。我们<br>做了如下几个设计：<br>1.使用更广的数据源：不仅仅使用推荐场景的数据，训练样本是从全部youtube观看记录中产生。防止对推荐者的观看记录过度利用，加入<br>对新视频的测试。<br>2.为用户生成固定数量的训练样本：每个用户在损失函数中的权重都是相等的，防止一小部分超级活跃用户影响到损失函数的公平性。<br>3.抛弃数据的序列信息：我们在实现时尝试的是去掉序列信息，对过去观看视频/历史搜索query的embedding向量进行加权平均。这点其实<br>违反直觉，可能原因是模型对负反馈没有很好的建模。<br>4.不对称的共同浏览问题：所谓asymmetric co-watch值的是用户在浏览视频时候，往往都是序列式的，开始看一些比较流行的，逐渐找到<br>细分的视频。下图(a)是hled-out方式，利用上下文信息预估中间的一个视频；图(b)是predicting next watch的方式，则是利用上文信息，<br>预估下一次浏览的视频。<br><img src="/2018/12/19/读-Deep-Neural-Networks-for-YouTube-Recommendations-总结/数据集划分.png" title="数据集划分"></p>
<h3 id="不同网络深度和特征的实验"><a href="#不同网络深度和特征的实验" class="headerlink" title="不同网络深度和特征的实验"></a>不同网络深度和特征的实验</h3><p>基本和前面图中所示的网络架构相同，所有的视频和search token都embedded到256维的向量中，开始input层直接全连接到256维的<br>softmax层，依次增加网络深度（+512–&gt;+1024–&gt;+2048–&gt; …）。<br><br>下图反映了不同网络深度（横坐标）下不同特征组合情况下的holdout-MAP（纵坐标）。可以很明显看出，增加了观看历史之外的特征很<br>明显的提升了预测得准确率；从网络深度看，随着网络深度加大，预测准确率在提升，但继续增加第四层网络已经收益不大了。<br><img src="/2018/12/19/读-Deep-Neural-Networks-for-YouTube-Recommendations-总结/特征和网络结构效果对比.png" title="特征和网络结构效果对比"></p>
<h3 id="离线训练及在线服务模块"><a href="#离线训练及在线服务模块" class="headerlink" title="离线训练及在线服务模块"></a>离线训练及在线服务模块</h3><p>激活函数使用relu，softmax层的输出是预测的视频分类结果，我们通过离线训练得到离线模型。同时得到用户向量u和视频向量v。得到视<br>频向量后我们可以将其保存起来，用于在线服务。实时计算用户向量u，然后与v做内积，得到topN。这里需要使用hashing算法加速查找<br>topN。</p>
<h3 id="个人理解"><a href="#个人理解" class="headerlink" title="个人理解"></a>个人理解</h3><p>1.特征里面的example age指的是样本时间，而不是网上所说的视频上传时间。论文也详细解释了，他可以很好的表示视频上传时间和时间<br>段上受欢迎程度。<br>2.用户向量u指的是输出层的前一层，而视频向量v指的是前一层到输出层的参数。所以训练完模型我们可以得到两个表示u和v，只不过用户<br>u我们后面实时计算。<br>3.输出层多分类时，当视频数量较大时，使用了负采样，提高计算效率。<br>4.实时计算topN时，当数据量比较大时，我们需要近似近邻查找来提升计算效率，但是会有一定精度损失。</p>
<h2 id="排序阶段"><a href="#排序阶段" class="headerlink" title="排序阶段"></a>排序阶段</h2><p>排序阶段的最重要任务就是精准的预估用户对视频的喜好程度。不同于召回阶段面临的是百万级候选视频集，排序阶段面对的只是百级别<br>的商品集，因此可以使用更多更精细的feature来刻画视频。此外，还可以和其他召回方式得来的数据进行ensemble。</p>
<h3 id="模型架构-1"><a href="#模型架构-1" class="headerlink" title="模型架构"></a>模型架构</h3><p>排序阶段的模型和召回阶段的基本相似，不同的是训练的最后一层是一个weighted LR层，而serving阶段激励函数用的是e^{x}。另外，优<br>化目标换成了期望的观看时长。<br><img src="/2018/12/19/读-Deep-Neural-Networks-for-YouTube-Recommendations-总结/排序模型架构.png" title="排序模型架构"></p>
<h3 id="特征处理"><a href="#特征处理" class="headerlink" title="特征处理"></a>特征处理</h3><p>1.特征工程：在搜索和推荐场景，我们的很难把原始数据直接作为FNN的输入，特征工程仍然很重要。而特征工程中最难的是如何建模用户<br>时序行为（temporal sequence of user actions）并且将这些行为和要排序的物品关联起来。youtube发现最重要的信息是描述用户与商<br>品本身或相似商品之间交互的信息。我们要度量用户对视频的喜欢，可以考虑用户与视频所在频道间的关系：<br>    a.数量特征：浏览该频道的次数？<br>    b.时间特征：比如最近一次浏览该频道距离现在的时间？<br>这两个连续特征的最大好处是具备非常强的泛化能力。另外除了这两个偏正向的特征，用户对于视频所在频道的一些PV但不点击的行为，<br>即负反馈信息同样非常重要。此外，还有推荐来源、所在来源分数等。<br>2.类别特征embedding：NN更适合处理连续特征，因此稀疏的特别是高基数空间的离散特征需要embedding到稠密的向量中。实际并非为<br>所有的id进行embedding，比如视频id，只需要按照点击排序，选择top N视频进行embedding，其余置为0向量。有些可以复用召回阶<br>段的embedding。<br>3.连续特征归一化：NN对输入特征的尺度和分布都是非常敏感的，实际上基本上除了Tree-Based的模型（比如GBDT/RF），机器学习的大<br>多算法都如此。我们发现归一化方法对收敛很关键，推荐一种排序分位归一到[0,1]区间的方法，即\bar{x}=\int_{-\infty }^{x}df ，<br>累计分位点。除此之外，我们还把归一化后的\bar{x} 的根号\sqrt{x} 和平方x^{2} 作为网络输入，以期能使网络能够更容易得到特征<br>的次线性（sub-linear）和（super-linear）超线性函数。</p>
<h3 id="建模期望观看时长"><a href="#建模期望观看时长" class="headerlink" title="建模期望观看时长"></a>建模期望观看时长</h3><p>youtube的目标是预测期望观看时长。有点击的为正样本，有PV无点击的为负样本，正样本需要根据观看时长进行加权。因此，我们训练阶<br>段网络最后一层用的是 weighted logistic regression。<br>正样本的权重为观看时长 T_{i}，负样本权重为1。这样的话，LR学到的odds为：<br><img src="/2018/12/19/读-Deep-Neural-Networks-for-YouTube-Recommendations-总结/期望观看时长.png" title="期望观看时长"><br>其中N是总的样本数量，k是正样本数量，T_{i}是第i正样本的观看时长。一般来说，k相对N比较小，因此上式的odds可以转换成<br>E[T]/(1+P)，其中P是点击率，点击率一般很小，这样odds接近于E[T]，即期望观看时长。因此在线上serving的inference阶段，我们采用<br>e^{x}作为激励函数，就是近似的估计期望的观看时长。</p>
<h3 id="不同隐层的实验"><a href="#不同隐层的实验" class="headerlink" title="不同隐层的实验"></a>不同隐层的实验</h3><p>隐层数的实验与召回阶段DNN的方法类似。</p>
<h3 id="个人理解-1"><a href="#个人理解-1" class="headerlink" title="个人理解"></a>个人理解</h3><p>1.不同的优化目标会有不同的优化结果，这里使用了期望观看时长，避免了ctr指标的情况下，标题的欺骗性，实际上没有观看。然而这样<br>会导致模型偏向于短视频，所以，可以根据自己实际需要选取。<br>2.特征工程处理的时候，可以采用常用的方案，分类数目多的时候，将排序靠后的数据处理成其他。归一化处理特征，增加非线性特征。<br>3.预测时使用了带权重的lr，让模型可以拟合期望时长。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://riverzzz.github.io/2018/12/19/读-Deep-Neural-Networks-for-YouTube-Recommendations-总结/" data-id="cjsahe8wi000y9sv3wpabpmtn" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2018/12/26/spiral-Matrix-II/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          spiral Matrix II
        
      </div>
    </a>
  
  
    <a href="/2018/12/11/读-Deep-contextualized-word-representations-总结/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">读 Deep contextualized word representations 总结</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/02/">February 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">January 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">December 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/11/">November 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">October 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/02/18/Reverse-Words-in-a-String/">Reverse Words in a String</a>
          </li>
        
          <li>
            <a href="/2019/02/18/Permutation-in-String/">Permutation in String</a>
          </li>
        
          <li>
            <a href="/2019/02/18/Longest-Substring-Without-Repeating-Characters/">Longest Substring Without Repeating Characters</a>
          </li>
        
          <li>
            <a href="/2019/02/11/Median-of-Two-Sorted-Arrays/">Median of Two Sorted Arrays</a>
          </li>
        
          <li>
            <a href="/2019/02/11/Binary-Tree-Maximum-Path-Sum/">Binary Tree Maximum Path Sum</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 riverzzz<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>